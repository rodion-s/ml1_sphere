{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Алгоритмы интеллектуальной обработки больших объемов данных\n",
    "## Домашнее задание №3 - Дерево решений\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Общая информация**\n",
    "\n",
    "**Срок сдачи:** 25 ноября 2019, 15:00   \n",
    "**Штраф за опоздание:** -2 балла после 15:00 25 ноября, -4 балла после 15:00 2 декабря, -6 баллов после 15:00 9 декабря  -8 баллов после 15:00 16 декабря.\n",
    "\n",
    "При отправлении ДЗ указывайте фамилию в названии файла Присылать ДЗ необходимо в виде ссылки на свой github репозиторий на почту ml1.sphere@mail.ru с указанием темы в следующем формате:\n",
    "[ML0919, Задание 3] Фамилия Имя. \n",
    "\n",
    "\n",
    "Используйте данный Ipython Notebook при оформлении домашнего задания."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Задание 1 (3 балла)\n",
    "Разберитесь в коде MyDecisionTreeClassifier, который уже частично реализован. Допишите код там, где написано \"Ваш код\". Ваша реализация дерева должна работать по точности не хуже DecisionTreeClassifier из sklearn. Точность проверяется на [wine](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_wine.html) и [Speed Dating Data](https://cloud.mail.ru/public/8nHV/p6J7wY1y1)\n",
    "\n",
    "###### Задание 2 (3 балла)\n",
    "Добиться скорости работы на fit не медленнее чем в 10 раз sklearn на данных wine и Speed Dating Data. \n",
    "Для этого используем numpy.\n",
    "\n",
    "###### Задание 3 (2 балла)\n",
    "Добавьте функционал, который определяет значения feature importance. Выведите 10 главных фичей под пунктом Задание 4 (уже написано ниже) для MyDecisionTreeClassifier и DecisionTreeClassifier так, чтобы сразу были видны выводы и по MyDecisionTreeClassifier, и по DecisionTreeClassifier. Используем данные Speed Dating Data.\n",
    "\n",
    "###### Задание 4 (2 балла)\n",
    "С помощью GridSearchCV или RandomSearchCV подберите наиболее оптимальные параметры для случайного леса (Выберете 2-3 параметра). Используем данные Speed Dating Data. Задание реализуйте под пунктом Задание 5 (уже написано ниже)\n",
    "\n",
    "\n",
    "**Штрафные баллы:**\n",
    "\n",
    "1. Невыполнение PEP8 -1 балл\n",
    "2. Отсутствие фамилии в имени скрипта (скрипт должен называться по аналогии со stroykova_hw3.ipynb) -1 балл\n",
    "3. Все строчки должны быть выполнены. Нужно, чтобы output команды можно было увидеть уже в git'е. В противном случае -1 балл\n",
    "4. При оформлении ДЗ нужно пользоваться данным файлом в качестве шаблона. Не нужно удалять и видоизменять написанный код и текст. В противном случае -1 балл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import KFold, train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MyDecisionTreeClassifier:\n",
    "    NON_LEAF_TYPE = 0\n",
    "    LEAF_TYPE = 1\n",
    "\n",
    "    def __init__(self, min_samples_split=2, max_depth=None, sufficient_share=1.0, criterion='gini', max_features=None):\n",
    "        self.tree = dict()\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        self.sufficient_share = sufficient_share\n",
    "        self.num_class = -1\n",
    "        self.feature_importances_ = None\n",
    "        self.imp = None\n",
    "        if criterion == 'gini':\n",
    "            self.G_function = self.__gini\n",
    "            self.imp = self.__gini_imp\n",
    "        elif criterion == 'entropy':\n",
    "            self.G_function = self.__entropy\n",
    "            self.imp = self.__entropy_imp\n",
    "        elif criterion == 'misclass':\n",
    "            self.G_function = self.__misclass\n",
    "            self.imp = self.__misclass_imp\n",
    "        else:\n",
    "            print('invalid criterion name')\n",
    "            raise\n",
    "\n",
    "        if max_features == 'sqrt':\n",
    "            self.get_feature_ids = self.__get_feature_ids_sqrt\n",
    "        elif max_features == 'log2':\n",
    "            self.get_feature_ids = self.__get_feature_ids_log2\n",
    "        elif max_features == None:\n",
    "            self.get_feature_ids = self.__get_feature_ids_N\n",
    "        else:\n",
    "            print('invalid max_features name')\n",
    "            raise\n",
    "\n",
    "    def __gini(self, l_c, l_s, r_c, r_s):\n",
    "        l_s = l_s.astype('float')\n",
    "        r_s = r_s.astype('float')\n",
    "        return 1 - (l_s * np.sum((l_c / l_s) ** 2, axis=1).reshape(-1, 1) +\\\n",
    "                r_s * np.sum((r_c / r_s) ** 2, axis=1).reshape(-1, 1)) / (l_s + r_s)\n",
    "    \n",
    "    def __entropy(self, l_c, l_s, r_c, r_s):\n",
    "        return -(l_s * (np.sum((l_c / l_s) * np.log(l_c / l_s), axis=1)).reshape(-1, 1) +\\\n",
    "                r_s * (np.sum((r_c / r_s) * np.log(r_c / r_s), axis=1)).reshape(-1, 1)) / (l_s + r_s)\n",
    "        \n",
    "    def __misclass(self, l_c, l_s, r_c, r_s):\n",
    "        return 1 - ((l_s * np.max(l_c / l_s, axis=1)).reshape(-1, 1) +\\\n",
    "                    (r_s * np.max(r_c / r_s, axis=1)).reshape(-1, 1)) / (l_s + r_s)\n",
    "\n",
    "    def __get_feature_ids_sqrt(self, n_feature):\n",
    "        feature_ids = range(n_feature)\n",
    "        np.random.shuffle(feature_ids)\n",
    "        return np.array(feautre_ids[:np.round(np.sqrt(n_feature))], dtype=int)\n",
    "        \n",
    "    def __get_feature_ids_log2(self, n_feature):\n",
    "        feature_ids = range(n_feature)\n",
    "        np.random.shuffle(feature_ids)\n",
    "        return np.array(feautre_ids[:np.round(np.log2(n_feature))], dtype=int)\n",
    "\n",
    "    def __get_feature_ids_N(self, n_feature):\n",
    "        return np.arange(n_feature)\n",
    "    \n",
    "    def __sort_samples(self, x, y):\n",
    "        sorted_idx = x.argsort()\n",
    "        return x[sorted_idx], y[sorted_idx]\n",
    "\n",
    "    def __div_samples(self, x, y, feature_id, threshold):\n",
    "        left_mask = x[:, feature_id] > threshold\n",
    "        right_mask = ~left_mask\n",
    "        return x[left_mask], x[right_mask], y[left_mask], y[right_mask]\n",
    "\n",
    "    \n",
    "    def __gini_imp(self, y):\n",
    "        return 1 - ((np.bincount(y).astype('float') / y.size) ** 2).sum()\n",
    "    \n",
    "    def __entropy_imp(self, y):\n",
    "        bins = np.bincount(y).astype('float') / y.size\n",
    "        return -np.nansum(bins * np.log2(bins))\n",
    "    \n",
    "    def __misclass_imp(self, y):\n",
    "        return 1 - np.max(np.bincount(y).astype('float') / y.size)\n",
    "    \n",
    "    \n",
    "    def __find_threshold(self, x, y):\n",
    "       \n",
    "        x_sorted, y_sorted = self.__sort_samples(x, y)\n",
    "        right_border_idx = np.where(y_sorted[:-1] != y_sorted[1:])[0] + 1\n",
    "        \n",
    "        if len(right_border_idx) == 0:\n",
    "            return np.inf, None\n",
    "        # [в строках - интервалы, на которых метка класса не меняется, в столбцах - метки класса]\n",
    "        # [в элементах - число объектов из данного интервала с данной меткой класса]\n",
    "        contiguous_elem_count = (right_border_idx - np.append(np.array([0]), right_border_idx[:-1])).reshape(-1, 1)\n",
    "        contiguous_matrix = np.zeros((right_border_idx.shape[0], self.num_class))\n",
    "        contiguous_matrix[np.arange(right_border_idx.shape[0]), y_sorted[right_border_idx - 1]] = 1\n",
    "        class_counts = contiguous_matrix * contiguous_elem_count\n",
    "        \n",
    "\n",
    "        left_classes_count = np.cumsum(class_counts, axis=0)\n",
    "        right_classes_count = np.bincount(y_sorted, minlength=self.num_class) - left_classes_count\n",
    "        left_sizes = right_border_idx.reshape(left_classes_count.shape[0], 1)\n",
    "        right_sizes = y_sorted.shape[0] - left_sizes\n",
    "\n",
    "        uncertainty = self.G_function(left_classes_count, left_sizes, right_classes_count, right_sizes)\n",
    "        min_idx = np.argmin(uncertainty)\n",
    "        \n",
    "        left_idx = left_sizes[min_idx][0]\n",
    "        threshold = (x_sorted[left_idx - 1] + x_sorted[left_idx]) / 2.0\n",
    "        return uncertainty[min_idx], threshold\n",
    "    \n",
    "    def __fit_node(self, x, y, node_id, depth):\n",
    "        count = np.bincount(y)\n",
    "        if self.max_depth is not None and depth == self.max_depth or\\\n",
    "                    y.shape[0] < self.min_samples_split or\\\n",
    "                    self.sufficient_share <= np.float(np.bincount(y).max()) / y.size:\n",
    "            self.tree[node_id] = (self.LEAF_TYPE, np.argmax(count), np.array(count, dtype=float) / y.size)\n",
    "            return\n",
    "        indices = self.get_feature_ids(x.shape[1])\n",
    "        thresholds = np.array([self.__find_threshold(x[:, idx], y) for idx in indices])\n",
    "        min_thr = thresholds[:, 0].argmin()\n",
    "        optimal_threshold = thresholds[min_thr, 1]\n",
    "\n",
    "        x_l, x_r, y_l, y_r = self.__div_samples(x, y, indices[min_thr], optimal_threshold)\n",
    "        \n",
    "        if x_l.shape[0] == 0 or x_r.shape[0] == 0:\n",
    "            self.tree[node_id] = (self.LEAF_TYPE, count.argmax(), count.astype('float') / y.size)\n",
    "            return\n",
    "\n",
    "        self.tree[node_id] = (self.NON_LEAF_TYPE, indices[min_thr], optimal_threshold)\n",
    "\n",
    "        self.feature_importances_[min_thr] += y.size * self.imp(y) -\\\n",
    "                                            y_l.size * self.imp(y_l) -\\\n",
    "                                            y_r.size * self.imp(y_r)\n",
    "\n",
    "        self.__fit_node(x_l, y_l, 2 * node_id + 1, depth + 1)\n",
    "        self.__fit_node(x_r, y_r, 2 * node_id + 2, depth + 1)\n",
    "\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        self.num_class = np.unique(y).size\n",
    "        self.feature_importances_ = np.zeros(x.shape[1], dtype=np.float)\n",
    "        self.__fit_node(x, y, 0, 0)\n",
    "        self.feature_importances_ /= self.feature_importances_.sum()\n",
    " \n",
    "\n",
    "    def __predict_class(self, x, node_id):\n",
    "        node = self.tree[node_id]\n",
    "        if node[0] == self.__class__.NON_LEAF_TYPE:\n",
    "            _, feature_id, threshold = node\n",
    "            if x[feature_id] > threshold:\n",
    "                return self.__predict_class(x, 2 * node_id + 1)\n",
    "            else:\n",
    "                return self.__predict_class(x, 2 * node_id + 2)\n",
    "        else:\n",
    "            return node[1]\n",
    "\n",
    "    def __predict_probs(self, x, node_id):\n",
    "        node = self.tree[node_id]\n",
    "        if node[0] == self.__class__.NON_LEAF_TYPE:\n",
    "            _, feature_id, threshold = node\n",
    "            if x[feature_id] > threshold:\n",
    "                return self.__predict_probs(x, 2 * node_id + 1)\n",
    "            else:\n",
    "                return self.__predict_probs(x, 2 * node_id + 2)\n",
    "        else:\n",
    "            return node[2]\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return np.array([self.__predict_class(x, 0) for x in X])\n",
    "    \n",
    "    def predict_probs(self, X):\n",
    "        return np.array([self.__predict_probs(x, 0) for x in X])\n",
    "\n",
    "    def fit_predict(self, x_train, y_train, predicted_x):\n",
    "        self.fit(x_train, y_train)\n",
    "        return self.predict(predicted_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_clf = MyDecisionTreeClassifier(min_samples_split=2)\n",
    "clf = DecisionTreeClassifier(min_samples_split=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = load_wine()\n",
    "X_train, X_test, y_train, y_test = train_test_split(wine.data, wine.target, test_size=0.1, stratify=wine.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка скорости работы на wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.55 ms, sys: 866 µs, total: 4.42 ms\n",
      "Wall time: 4.08 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.5 ms, sys: 616 µs, total: 19.2 ms\n",
      "Wall time: 16.9 ms\n"
     ]
    }
   ],
   "source": [
    "%time my_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка качества работы на wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9440559440559441"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=clf.predict(X_test), y_true=y_test, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9440559440559441"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=my_clf.predict(X_test), y_true=y_test, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных Speed Dating Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iid</th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>idg</th>\n",
       "      <th>condtn</th>\n",
       "      <th>wave</th>\n",
       "      <th>round</th>\n",
       "      <th>position</th>\n",
       "      <th>positin1</th>\n",
       "      <th>order</th>\n",
       "      <th>...</th>\n",
       "      <th>attr3_3</th>\n",
       "      <th>sinc3_3</th>\n",
       "      <th>intel3_3</th>\n",
       "      <th>fun3_3</th>\n",
       "      <th>amb3_3</th>\n",
       "      <th>attr5_3</th>\n",
       "      <th>sinc5_3</th>\n",
       "      <th>intel5_3</th>\n",
       "      <th>fun5_3</th>\n",
       "      <th>amb5_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8373</th>\n",
       "      <td>552</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>14</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8374</th>\n",
       "      <td>552</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>13</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8375</th>\n",
       "      <td>552</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>19</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8376</th>\n",
       "      <td>552</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>10.0</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8377</th>\n",
       "      <td>552</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8378 rows × 195 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      iid    id  gender  idg  condtn  wave  round  position  positin1  order  \\\n",
       "0       1   1.0       0    1       1     1     10         7       NaN      4   \n",
       "1       1   1.0       0    1       1     1     10         7       NaN      3   \n",
       "2       1   1.0       0    1       1     1     10         7       NaN     10   \n",
       "3       1   1.0       0    1       1     1     10         7       NaN      5   \n",
       "4       1   1.0       0    1       1     1     10         7       NaN      7   \n",
       "...   ...   ...     ...  ...     ...   ...    ...       ...       ...    ...   \n",
       "8373  552  22.0       1   44       2    21     22        14      10.0      5   \n",
       "8374  552  22.0       1   44       2    21     22        13      10.0      4   \n",
       "8375  552  22.0       1   44       2    21     22        19      10.0     10   \n",
       "8376  552  22.0       1   44       2    21     22         3      10.0     16   \n",
       "8377  552   NaN       1   44       2    21     22         2      10.0     15   \n",
       "\n",
       "      ...  attr3_3  sinc3_3  intel3_3  fun3_3  amb3_3  attr5_3  sinc5_3  \\\n",
       "0     ...      5.0      7.0       7.0     7.0     7.0      NaN      NaN   \n",
       "1     ...      5.0      7.0       7.0     7.0     7.0      NaN      NaN   \n",
       "2     ...      5.0      7.0       7.0     7.0     7.0      NaN      NaN   \n",
       "3     ...      5.0      7.0       7.0     7.0     7.0      NaN      NaN   \n",
       "4     ...      5.0      7.0       7.0     7.0     7.0      NaN      NaN   \n",
       "...   ...      ...      ...       ...     ...     ...      ...      ...   \n",
       "8373  ...      8.0      5.0       7.0     6.0     7.0      9.0      5.0   \n",
       "8374  ...      8.0      5.0       7.0     6.0     7.0      9.0      5.0   \n",
       "8375  ...      8.0      5.0       7.0     6.0     7.0      9.0      5.0   \n",
       "8376  ...      8.0      5.0       7.0     6.0     7.0      9.0      5.0   \n",
       "8377  ...      8.0      5.0       7.0     6.0     7.0      9.0      5.0   \n",
       "\n",
       "      intel5_3  fun5_3  amb5_3  \n",
       "0          NaN     NaN     NaN  \n",
       "1          NaN     NaN     NaN  \n",
       "2          NaN     NaN     NaN  \n",
       "3          NaN     NaN     NaN  \n",
       "4          NaN     NaN     NaN  \n",
       "...        ...     ...     ...  \n",
       "8373       9.0     5.0     6.0  \n",
       "8374       9.0     5.0     6.0  \n",
       "8375       9.0     5.0     6.0  \n",
       "8376       9.0     5.0     6.0  \n",
       "8377       9.0     5.0     6.0  \n",
       "\n",
       "[8378 rows x 195 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = df = pd.read_csv('Speed Dating Data.csv', encoding='cp1251')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#По аналогии с тем, что было на семинаре + некоторый рефакторинг для читаемости\n",
    "\n",
    "droplist = ['id', 'idg', 'condtn', 'round', 'position', 'positin1', 'order', 'partner',\n",
    "            'age_o', 'race_o', 'pf_o_att',\n",
    "            'pf_o_sin', 'pf_o_int',\n",
    "            'pf_o_fun', 'pf_o_amb', 'pf_o_sha',\n",
    "            'dec_o', 'attr_o', 'sinc_o', 'intel_o', 'fun_o',\n",
    "            'amb_o', 'shar_o', 'like_o', 'prob_o', 'met_o',\n",
    "            'field', 'undergra', 'from', 'zipcode', 'career',\n",
    "            'sports', 'tvsports', 'exercise',\n",
    "            'dining', 'museums', 'art', 'hiking',\n",
    "            'gaming', 'clubbing', 'reading', 'tv',\n",
    "            'theater', 'movies', 'concerts',\n",
    "            'music', 'shopping', 'yoga',\n",
    "            'expnum', 'wave']\n",
    "\n",
    "df = df.iloc[:, :97]\n",
    "\n",
    "df = df.drop(droplist, axis=1)\n",
    "\n",
    "\n",
    "dropnalist = ['age', 'imprelig', 'imprace', 'date']\n",
    "df.dropna(subset=dropnalist)\n",
    "\n",
    "pd.get_dummies(df, columns=['field_cd'], prefix='field_cd', prefix_sep='=')\n",
    "\n",
    "df.loc[:, 'mn_sat'] = df.loc[:, 'mn_sat'].str.replace(',', '').astype(np.float)\n",
    "df.loc[:, 'tuition'] = df.loc[:, 'tuition'].str.replace(',', '').astype(np.float)\n",
    "df.loc[:, 'income'] = df.loc[:, 'income'].str.replace(',', '').astype(np.float)\n",
    "\n",
    "\n",
    "buf = ['field_cd', 'mn_sat', 'tuition', 'income', 'career_c']\n",
    "df.loc[:, buf] = df.loc[:, buf].fillna(0)\n",
    "\n",
    "\n",
    "\n",
    "df.loc[:, 'temp_totalsum'] = df.loc[:, ['attr1_1', 'sinc1_1', 'intel1_1',\n",
    "                                        'fun1_1', 'amb1_1', 'shar1_1']].sum(axis=1)\n",
    "\n",
    "df.loc[:, ['attr1_1', 'sinc1_1',\n",
    "           'intel1_1', 'fun1_1',\n",
    "           'amb1_1', 'shar1_1']] = \\\n",
    "    (df.loc[:, ['attr1_1', 'sinc1_1',\n",
    "                'intel1_1', 'fun1_1',\n",
    "                'amb1_1', 'shar1_1']].T / df.loc[:, 'temp_totalsum'].T).T * 100\n",
    "\n",
    "df.loc[:, 'temp_totalsum'] = df.loc[:, ['attr2_1', 'sinc2_1',\n",
    "                                        'intel2_1', 'fun2_1',\n",
    "                                        'amb2_1', 'shar2_1']].sum(axis=1)\n",
    "\n",
    "df.loc[:, ['attr2_1', 'sinc2_1',\n",
    "           'intel2_1', 'fun2_1',\n",
    "           'amb2_1', 'shar2_1']] = \\\n",
    "    (df.loc[:, ['attr2_1', 'sinc2_1', 'intel2_1', 'fun2_1',\n",
    "                'amb2_1', 'shar2_1']].T / df.loc[:, 'temp_totalsum'].T).T * 100\n",
    "\n",
    "df = df.drop(['temp_totalsum'], axis=1)\n",
    "\n",
    "\n",
    "for i in [4, 5]:\n",
    "    feat = ['attr{}_1'.format(i), 'sinc{}_1'.format(i),\n",
    "            'intel{}_1'.format(i), 'fun{}_1'.format(i),\n",
    "            'amb{}_1'.format(i), 'shar{}_1'.format(i)]\n",
    "\n",
    "    if i != 4:\n",
    "        feat.remove('shar{}_1'.format(i))\n",
    "\n",
    "    df = df.drop(feat, axis=1)\n",
    "\n",
    "\n",
    "df_male = df.query('gender == 1').drop_duplicates(subset=['iid', 'pid']) \\\n",
    "    .drop(['gender'], axis=1).dropna()\n",
    "df_female = df.query('gender == 0').drop_duplicates(subset=['iid']) \\\n",
    "    .drop(['gender', 'match', 'int_corr', 'samerace'], axis=1).dropna()\n",
    "\n",
    "df_female.columns = df_female.columns + '_f'\n",
    "df_female = df_female.drop(['pid_f'], axis=1)\n",
    "df_pair = df_male.join(df_female.set_index('iid_f'), on='pid', how='inner')\n",
    "df_pair = df_pair.drop(['iid', 'pid'], axis=1)\n",
    "\n",
    "X = df_pair.iloc[:, 1:].values\n",
    "y = df_pair.iloc[:, 0].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка скорости работы на Speed Dating Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.9 ms, sys: 565 µs, total: 23.4 ms\n",
      "Wall time: 22.2 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 266 ms, sys: 4.07 ms, total: 270 ms\n",
      "Wall time: 268 ms\n"
     ]
    }
   ],
   "source": [
    "%time my_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка качества работы на Speed Dating Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5205294532248623"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=clf.predict(X_test), y_true=y_test, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5163720590028038"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=my_clf.predict(X_test), y_true=y_test, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 3 + Задание 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <th>clfImportance</th>\n",
       "      <th>MyDecisionTreeClassifier</th>\n",
       "      <th>my_clfImportance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>int_corr</td>\n",
       "      <td>0.089783</td>\n",
       "      <td>int_corr</td>\n",
       "      <td>0.091102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>income_s</td>\n",
       "      <td>0.035453</td>\n",
       "      <td>intel1_1</td>\n",
       "      <td>0.084840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>exphappy_s</td>\n",
       "      <td>0.034957</td>\n",
       "      <td>exphappy_s</td>\n",
       "      <td>0.084612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>age_s</td>\n",
       "      <td>0.033850</td>\n",
       "      <td>fun4_1_s</td>\n",
       "      <td>0.082582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>shar1_1_s</td>\n",
       "      <td>0.029054</td>\n",
       "      <td>imprelig_s</td>\n",
       "      <td>0.079305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sinc1_1_s</td>\n",
       "      <td>0.027828</td>\n",
       "      <td>fun1_1</td>\n",
       "      <td>0.074468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>attr2_1</td>\n",
       "      <td>0.027188</td>\n",
       "      <td>tuition_s</td>\n",
       "      <td>0.060672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>amb1_1</td>\n",
       "      <td>0.026578</td>\n",
       "      <td>age</td>\n",
       "      <td>0.058987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mn_sat</td>\n",
       "      <td>0.023017</td>\n",
       "      <td>amb3_1_s</td>\n",
       "      <td>0.055364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>shar1_1</td>\n",
       "      <td>0.022830</td>\n",
       "      <td>samerace</td>\n",
       "      <td>0.049156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  DecisionTreeClassifier  clfImportance MyDecisionTreeClassifier  \\\n",
       "0               int_corr       0.089783                 int_corr   \n",
       "1               income_s       0.035453                 intel1_1   \n",
       "2             exphappy_s       0.034957               exphappy_s   \n",
       "3                  age_s       0.033850                 fun4_1_s   \n",
       "4              shar1_1_s       0.029054               imprelig_s   \n",
       "5              sinc1_1_s       0.027828                   fun1_1   \n",
       "6                attr2_1       0.027188                tuition_s   \n",
       "7                 amb1_1       0.026578                      age   \n",
       "8                 mn_sat       0.023017                 amb3_1_s   \n",
       "9                shar1_1       0.022830                 samerace   \n",
       "\n",
       "   my_clfImportance  \n",
       "0          0.091102  \n",
       "1          0.084840  \n",
       "2          0.084612  \n",
       "3          0.082582  \n",
       "4          0.079305  \n",
       "5          0.074468  \n",
       "6          0.060672  \n",
       "7          0.058987  \n",
       "8          0.055364  \n",
       "9          0.049156  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = np.argsort(clf.feature_importances_)[::-1][:10]\n",
    "clf_imp = df_pair.columns[1:][idx]\n",
    "my_idx = np.argsort(my_clf.feature_importances_)[::-1][:10]\n",
    "my_clf_imp = df_pair.columns[1:][my_idx]\n",
    "\n",
    "importances = pd.DataFrame(columns=['DecisionTreeClassifier', 'clfImportance',\n",
    "                                   'MyDecisionTreeClassifier', 'my_clfImportance'])\n",
    "importances['MyDecisionTreeClassifier'] = my_clf_imp\n",
    "importances['DecisionTreeClassifier'] = clf_imp\n",
    "importances['clfImportance'] = clf.feature_importances_[idx]\n",
    "importances['my_clfImportance'] = my_clf.feature_importances_[my_idx]\n",
    "importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 91,\n",
       " 'min_samples_leaf': 10,\n",
       " 'max_depth': 3,\n",
       " 'criterion': 'gini'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'max_depth': range(1, 15),\n",
    "    'min_samples_leaf': range(1, 20),\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'n_estimators': range(1, 100, 10)\n",
    "}\n",
    "forest = RandomForestClassifier()\n",
    "optimal_clf = RandomizedSearchCV(forest, param_distributions=params, cv = 5)\n",
    "optimal_clf.fit(X_train, y_train)\n",
    "optimal_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodion/miniconda3/envs/sphere-py37/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.46171693735498837"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=optimal_clf.best_estimator_.predict(X_test), y_true=y_test, average='macro')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
